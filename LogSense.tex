\documentclass{report}
\usepackage{titlesec}

\titleformat{\chapter}[display]
  {\normalfont\huge\bfseries}{}{0pt}{\Huge}

\usepackage[letterpaper,top=2cm,bottom=2cm,left=3cm,right=3cm,marginparwidth=1.75cm]{geometry}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage[colorlinks=true, allcolors=blue]{hyperref}
\usepackage{todonotes}
\usepackage{babel}
\usepackage[numbers,comma,square]{natbib}
\usepackage[utf8]{inputenc}
\usepackage{fancyhdr}
\usepackage{grffile}

\pagestyle{fancy}
\fancyhf{}
\rhead{LogSense}
\lhead{HTL Perg}
\renewcommand{\headrulewidth}{0pt}



\fancypagestyle{plain}{
  \fancyhf{}
  \rhead{LogSense}
  \lhead{HTL Perg}
  \fancyfoot[R]{\thepage}
  \fancyfoot[L]{Borbely, Ettlinger, Jilek, Stadlbauer}
  \renewcommand{\headrulewidth}{0pt}
}


\fancyfoot{}
\fancyfoot[R]{\thepage} % Page number format on the right side
\fancyfoot[L]{Borbely, Ettlinger, Jilek, Stadlbauer} % Names on the left side
\begin{document}

\begin{figure}[htp]
    \centering
    \includegraphics[width=4cm, height=4cm]{LatexStyleFiles/htl_perg.png}
    \caption{Graph mit erkannten Anoalien}
\end{figure}

\tableofcontents

\chapter*{Eidesstattliche Erklärung}
This chapter introduces the background and motivation behind the software engineering project.

\chapter*{Gender-Erklärung}
Define the scope of the project, including any limitations and constraints.

\chapter*{Danksagung}
Summarize relevant literature and related work in the field of software engineering.

\chapter*{Impressum}
Clearly state the problem the project aims to address.

\chapter*{Kurzfassung}
Define the specific objectives and goals of the software engineering project.
\textbf{Problemstellung} 

\chapter*{Abstract}
Define the specific objectives and goals of the software engineering project.

\chapter*{Inhaltsverzeichnis}

\chapter{Einleitung}
\section{Ausgangssituation}
\section{Problemstellung}
\section{Zielsetzung}
\section{Projektinhalt}
Eine übersichtliche Projektstruktur ist eine Notwendigkeit, um die Projektziele zu erreichen. Die Diplomarbeit besteht aus den folgenden 5 Hauptkomponenten:
\subsection{Agent}
Der Agent erfasst alle 10 Sekunden Daten über die Hardware-Komponenten eines Rechners, auf dem das Betriebssystem Windows läuft. Nach der Datenerfassung fasst der Agent die Daten der letzten 60 Sekunden zusammen und bereitet sie auf, bevor er sie zur weiteren Analyse an den Server sendet. Bei der ersten Datenerfassung werden zusätzlich allgemeine Daten über den Rechner erfasst und beim Senden an den Server signalisiert das den Start einer Session.
\subsection{Analyse}
\subsection{Schnittstellen}
\subsection{Datenspeicherung}
\subsection{User Interface}
Die Benutzeroberfläche zeigt die analysierten Daten in Form von Diagrammen und Statistiken übersichtlich an. Beim erstmaligen Aufrufen der Benutzeroberläche kann ein Gerät ausgewählt werden, dessen Daten dargestellt werden. Weiters können die Benutzer eigens definierte Warnungen für ein Gerät erstellen, indem sie die Art der Diagnose und den jeweiligen Grenzwert angeben.
\section{Projektumfeld}
\subsection{Projektteam}
Das Projektteam besteht aus 4 Schülern der HTL Perg und die Verantwortlichkeiten haben sich dabei wie folgt aufgeteilt:
\begin{itemize}
    \item Philipp Borbely - Datenanalyse und -auswertung
    \item Sarah Ettlinger - Datenerfassung
    \item Thomas Jilek - Datenspeicherung und Systemintegration
    \item Emily Stadlbauer - Visualisierung und Anzeige
\end{itemize}

\subsection{Auftraggeber}

\chapter{Theoretische und fachpraktische Grundlagen und Methoden}
\section{Visualiserung}
\subsection{Angular}
\subsection{Charst JS}
\text
Chart.js ist eine JavaScript Bibliothek mit deren Hilfe man unterschiedliche Diagrammtypen in Webanwendungen darstellen kann. 
Es können 8 unterschiedliche Diagrammarten dargestellt werden, darunter: 
\begin{itemize}
    \item Liniendiagramme
    \item Balkendiagramme
    \item Bereichsdiagramme
    \item Kreisdiagramme
    \item Tortendiagramme
    \item Radardiagramme
    \item Polar Diagramme
    \item Streudiagramme
\end{itemize}
Die Bibliothek bietet unterschiedlieche, interaktive Funktionen wie Tooltipps und Animationen. 
Darüber hinaus gibt es viele Möglichkeiten mit verschiedenen Optionen und Konfigurationen das Diagramm nach eigenen Wünschen  anzupassen. 
Chart.js unterstützt responsives Design und kann sich an unterschiedliche Bildschirmgrößen anpassen.\\In dieser Diplomarbeit ist Chart.js im Angular Projekt eingebunden um unterschiedliche Messwerte grafisch darzustellen.
\subsection{BootStrap}
\subsection{Angular Material}

\section{Datenverarbeitung}
\subsection{Python}
\subsection{Pandas}
Pandas ist eine Python-Bibliothek zur Datenverarbeitung und -analyse. Sie stellt verschiedene Datenstrukturen und Funktionen für das Manipulieren von tabellarischen und strukturierten Daten zur Verfügung. Zu den wichtigsten Strukturen gehören DataFrames und Series.
\begin{itemize}
    \item \textbf{Series} \\
    \begin{minipage}[t]{\linewidth}
        Series sind eindimensionale, array-ähnliche Objekte, die wie eine einzelne Spalte in einer Tabelle angeordnet sind.
    \end{minipage}

    \item \textbf{DataFrames} \\
    \begin{minipage}[t]{\linewidth}
        Bei DataFrames handelt es sich um zweidimensionale Tabellen mit Zeilen und Spalten. Einzelne Spalten von einem DataFrame können dabei verschiedene Datentypen aufweisen. Zu den wichtigsten Funktionen gehören Aggregationen, Gruppierungen und Statistische Operationen. 
    \end{minipage}
\end{itemize}
  In der vorliegenden Diplomarbeit wird Pandas bei der Datenverarbeitung eingesetzt, insbesondere in Kombination mit Scikit-Learn, Numpy und Ruptures.
  Features bei denen Pandas eingesetzt wird:
  \begin{itemize}
      \item Anomalien
      \item Change-Points
      \item Bereinigung von Datensätzen
      \item Aggregation von Datensätzen
  \end{itemize}

\bibliographystyle{plain}
\bibliography{data_science}

\subsection{Numpy}
\subsection{Scikit-Learn}
\subsection{Ruptures}
\subsection{Algorithmen}

\section{Datenerfassung}
In den nachfolgenden Abschnitten werden die im Projekt verwendeten Konzepte und Technologien für die Datenerfassung beschrieben.

\subsection{Agent}
Für die Erfassung der Ressourcendaten wird ein sogennanter Agent verwendet. Dieser kann selbstständig, das heißt ohne das Zutun eines Benutzers oder eines anderen Programmes, Tätigkeiten und Prozesse ausführen. Das heißt, der Agent wartet so lange bis eine gewisse Zeit abgelaufen, ein Programm gestartet worden oder ein Ereignis jeglicher Art festgestellt worden ist und erledigt darauf bestimmte Aufgaben.\\
Dabei gibt es im wesentlichen 3 Arten von Agenten:
\begin{itemize}
    \item Reaktive Agenten
        \begin{description}
            \item Reaktive Agenten beobachten die Umgebung, auf der sie laufen und treffen Entscheidungen basierend auf den erfassten Daten.
        \end{description}
    \item Adaptive Agenten
        \begin{description}
            \item Diese Art von Agenten handelt, im Vergleich zu reaktiven Agenten, zusätzlich basierend auf bereits zuvor erfassten Daten und erkannten Zusammenhängen zwischen den Informationspunkten.
        \end{description}
    \item Kognitive Agenten
        \begin{description}
            \item Kognitive Agenten können weiters aus den erfassten Daten Muster lernen und selbstständig abwägen, welche Aufgaben wann und wie durchgeführt werden sollen, um bestmöglich auf die aktualle Situation der Umgebung reagieren zu können.
        \end{description}
\end{itemize}
Für diesen Anwendungsfall wird ein reaktiver Agent verwendet. Nach Ablauf von 60 Sekunden werden die Daten gemessen, je nach Art der Daten zusammengefasst und anschließend in einem geeigneten Format zur Auswertung an den Server gesendet. Es wird also überprüft, um welche Daten es sich handelt und daraufhin entschieden wie die Daten für das Senden vorbereitet werden sollen.

\subsection{Java}
Die Programmiersprache Java ist objektorientiert, besitzt eine einfache Syntax mit überschaubarem Sprachumfang und ist durch kontrollierte Speicherzugriffe sicher. Wenn es eine passende JVM (= Java Virtual Machine) für das Betriebssystem gibt, kann das Programm auf diesem Betriebssytem laufen. Diese Plattformunabhängigkeit wird dadurch ermöglicht, dass der Java-Quellcode in Bytecode übersetzt wird, der dann von der JVM interpretiert werden kann.\\
Der Agent, der lokal auf den Windows Rechnern läuft und die Daten über den Ressourcenverbrauch des Rechners erfasst, ist in der Programmiersprache Java entwickelt. Der Grund dafür ist, dass es für Java viele verschiedene Bibliotheken gibt, die auf die Hardwaretreiber zugreifen, um die benötigten Daten über den Rechner, die darauf laufenden Programme und deren Ressourcenverbrauch auszulesen.

\subsection{Oshi}
Oshi\footnote{\url{https://www.oshi.ooo/}} (= Operating System and Hardware Information) ist eine für die Programmiersprache Java entwickelte Bibliothek, die Daten über die Hardware und das Betriebssystem eines Rechners erfassen und bereitstellen kann. Dafür wird im Hintergrund die JNA-Bibliothek (= Java Native Access) verwendet. Diese dient als eine plattformunabhängige Schicht zwischen dem Programmcode der Oshi-Bibliothek und dem nativen Code, der abhängig vom Betriebsystem die Systeminformationen ausliest. Aus diesem Grund kann Oshi Daten über unterschiedliche Betriebssysteme, unter anderem Windows, Linux, macOs und verschiedene Unix Distributionen, erfassen.

\section{Datenhaltung}
\subsection{Postgres}
\subsection{Timescale DB}

\section{Schnittstellen}
\subsection{Fast API}
\subsection{REST}

\section{Server}
\subsection{Ubuntu}
\subsection{nginx}

\section{Entwicklungssysteme}
\subsection{PyCharm}
\subsection{IntelliJ}
\subsection{Webstorm}
\subsection{Datagrip}
\section{Sonstige Software}
\subsection{GitLab}
\subsection{Adobe XD}
\subsection{LucidChart}

\chapter{Planung und Realisierung}
\section{Funktionalität (UC, UC-Beschreibung)}
\section{Architektur}
\section{Informationsfluss}
\section{Datenmodell}

\chapter{Implementierung (Programmierung und QS/Test)}
\section{Visualiserung}
\section{Datenverarbeitung}
\subsection{Zusammenführung}
Da der Agent den Hardware-Verbrauch pro laufenden Prozess misst, die Applikation aber den Hardware-Verbrauch von Applikationen und den gesamten Rechner darstellt, müssen vor der Persistierung von Daten diese zunächst zusammengeführt werden. Zum Zweck der Bererechnung des gesamten PC-Verbrauchs wird die groupby-Methode von Pandas verwendet welche Daten pro Timestamp zusammenführt und die einzelnen Werte dabei summiert.
\subsection{Anomalienerkennung}
Ein Ziel der Anwendung ist es, bei den PC- und Anwedungsdaten Extremwerte und Abweichungen zu identifzieren und diese für den Benutzer zu markieren. Anomalienerkennung bei dieser Diplomarbeit hat den Sinn, ungewöhnliches Verhalten von Applikationen den Benutzer aufzuzeigen und anhand dessen ihn bei der Erkennung von Problemen beim Rechner behilflich zu sein. In Kombination mit Justifications bekommt dieser Hinweise darauf, weswegen diese Extremwerte zustandekommen. Auch allgemein spielt die Erkennung von Extremwerten bzw. Anomalien eine große Rolle im Datenverarbeitungsbereich, hauptsächlich aufgrund der Bereinigung von Datensätzen.
\subsubsection{Implementierungsmöglichkeiten}
Für das Erkennen von Extremwerten bieten sich eine Vielzahl von Möglichkeiten an, dazu zählen etwa das Aufteilen der Datensätze in Quantile, das Verwenden von Machine-Learning Algorithmen wie Isolation Forest und K-means oder das Anwenden von Stastisischen Methoden in Verbindung mit eigenen Algorithmen. 
\subsubsection{Händische Implementierung}
Im ersten Schritt werden Extremwerte anhand von bestimmten, prozentuellen Abweichungen vom gleitenden Durschnitt erkannt worden.Zunächst wird dafür der dafür der gleitende Durschnitt von Datensätzen berechnet worden und dann die prozentuelle Änderung von einem Datenpunkt zum gleitenden Durschnitt. Überschreitet dieser Wert eine definierte Grenze, beispielsweise 30 Prozent überschreiten, wird der Datenpunkt als Extremwert identifiziert.
Diese Vorgehensweise ist zwar ausreichend für das Erkennen von den meisten Extremwert-Punkten, jedoch nicht geeignet für Daten welche hohe Varianz aufweisen. \todo{Konkretes, praktisches beispiel}
\subsubsection{Anomalienerkennung mit Isolation Forest}
Zur Anomalienerkennung ist der Machine-Learning-Algorithmus Isolation Forest zur Verwendung gekommen. Dieser basiert auf das Konzept der Isolation, also der Tatsache, dass Anomalien weniger isoliert sind als herkömmliche Datenpunkte. 
Die Anomalienerkennung mit dem Machine-Learning-Algorithmus Isolation Forest hat gegenüber der Händischen Implementierung und statistischen Methoden wie Z-Scores den Vorteil, dass es keinerleine Annahmen über die Verteilung unserer Daten benötigt und problemlos mit Daten hoher Varianz arbeiten kann.
Bei der Implementierung sind Probleme bezüglich Underfitting aufgretreten falls nur eine geringe Menge an Datensätzen zum Trainieren des Algorithmus verfügbar gewesen ist. Dies ist der Fall, wenn der Benutzer die Datenanalyse in einem Zeitrahmen anfordert wo nur eine geringe Menge an Datensätzen verfügbar ist. Als Lösung sind zum Tranieren des Algorithmus nicht nur die Daten im gewählten Zeitrahmen genommen worden, sondern auch vorherliegende Datensätze. 
\subsection{Change Point Detection}
Zusätzlich zur Anomanlienerkennung wird bei LogSense auch das Erkennen von Change Points benötigt zur Identififzierung von Events und zum Feststellen von Trends zwischen Change Points. Change Points sind Zeitpunkte in einer Zeitreihe bei denen sich das Verhalten der Dateen oder statistische Eigenschaft signifikant ändern, beispielsweise gibt es einen enormen Anstieg oder Abfall bei den Daten. Angewendet wird dafür der Pelt(Pruned Exact Linear Time)-Algorithmus der ruptures-Bibliothek. Der Algorithmus basiert au
\subsection{Forecast}
\subsection{Userdefinierte Alerts}
\subsection{Justifications}
\section{Datenerfassung}
\section{Datenhaltung}
\subsection{Datenbank}
\subsubsection{Einleitung}
Die verwendete Datenbank ist TimescaleDB, welche auf Postgres aufbaut, der Vorteil dessen ist es, dass sowohl relationale Datenstrukturen, als auch die für Timeseries Data optimierten, sogenannten "Hypertable" zur verfügung stehen. Ein Vorteil dessen ist, dass TimescaleDB schnelle Lese -und Schreibgeschwindigkeiten für große Mengen an Timeseries-Daten anbietet, etwa wie die vom Agent gemessen Datensätze.

\title{Warum wird eine Datenbank benötigt?}
Die vom Agent gemessen Daten müssen für spätere analyse und visualisierung persistiert werden. Weiters wird die wird die Datenbank zum abspeichern von Benutzerinformationen verwendet.

\subsubsection{Datenmodell}
\subsubsection{Datenkatalog}
Der Datenkatalog beschreibt die einzelnen Tabellen, deren Funktion und die jeweiligen Attribute.
\subsection{Einfügen in Datenbank}
\section{Schnittstellen}
\section{Server}


\chapter{Ergebnis}
\section{Statistiken und Charts}
\section{Anomalien}
\section{Alerts}
\section{Ausblick}

\chapter{Resümee}


\chapter*{Quellverzeichnis}
Pandas \citep{pandas_docs}.

\chapter*{Abbildungsverzeichnis}

\chapter*{Glossar}

\chapter*{Anhang}
\section{Architekturskizze}
\section{Datenmodell}
\section{Diplomarbeitsplakat}
\section{Abnahmeformular}

\end{document}
